{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weight Initialization in Neural Networks\n",
        "#### why **weight initialization** is needed? [Read More]('https://www.pinecone.io/learn/weight-initialization/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZd6rozL3VIM"
      },
      "source": [
        "#### üß™ Naive Initialization (Bad Idea)\n",
        "- Initialize Weights to Zero\n",
        "    If all weights ùëä are initialized to zero:\n",
        "    - All neurons in the same layer learn the same gradients.\n",
        "\n",
        "    - This causes symmetry; effectively, only one neuron is learning.\n",
        "\n",
        "    - The network never learns diverse representations.\n",
        "\n",
        "‚ùå Leads to symmetry problem and poor learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "-0CJPXS83kxQ",
        "outputId": "d3829246-25f1-45fa-aae3-d4306c9d1270"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../../datasets/ushape.csv', names=['X', 'Y', 'class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yjwHpySv3nD6",
        "outputId": "0d452dcf-eed6-4304-c126-9d57bdc3f52c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.031595</td>\n",
              "      <td>0.986988</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.115098</td>\n",
              "      <td>-0.046244</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.882490</td>\n",
              "      <td>-0.075756</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.055144</td>\n",
              "      <td>-0.037332</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.829545</td>\n",
              "      <td>-0.539321</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          X         Y  class\n",
              "0  0.031595  0.986988    0.0\n",
              "1  2.115098 -0.046244    1.0\n",
              "2  0.882490 -0.075756    0.0\n",
              "3 -0.055144 -0.037332    1.0\n",
              "4  0.829545 -0.539321    1.0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gzRfDEgj3nzK",
        "outputId": "a42e8ce8-679b-4d42-a01f-41a378e793c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x1b541ae3ee0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(df['X'], df['Y'], c=df['class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VueL_H_-4Fxr"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 0:2].values\n",
        "y = df.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aLJYMP274XIV"
      },
      "outputs": [],
      "source": [
        "# import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### With ReLU and Tanh Activation Functions, What Happens if We Initialize Weights as 0?\n",
        "\n",
        "#### ReLU (Rectified Linear Unit)\n",
        "- **Symmetry Problem**: If all weights are initialized to 0, every neuron in the network will compute the same output during the forward pass. This is because the gradient of the loss with respect to the weights will be identical for all neurons.\n",
        "- **No Learning**: During backpropagation, the gradients for all weights will be the same, and the network will fail to break symmetry. As a result, all neurons in a layer will learn the same features, effectively reducing the capacity of the network.\n",
        "- **Dead Neurons**: ReLU activation can lead to \"dead neurons\" where some neurons output 0 for all inputs. If weights are initialized to 0, this problem is exacerbated because the neurons may never activate and learn.\n",
        "\n",
        "#### Tanh (Hyperbolic Tangent)\n",
        "- **Symmetry Problem**: Similar to ReLU, initializing weights to 0 causes all neurons to compute the same output and gradients, leading to symmetry that the network cannot break.\n",
        "- **Vanishing Gradients**: Tanh activation outputs values in the range [-1, 1]. If weights are initialized to 0, the gradients during backpropagation may become very small, slowing down or completely halting learning.\n",
        "\n",
        "- For ReLU, dead neurons can become a significant problem, while for Tanh, vanishing gradients can hinder training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 3)                 9         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "relu_model = Sequential()\n",
        "\n",
        "relu_model.add(Dense(3, activation='relu', input_dim=2))\n",
        "relu_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "relu_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0.49714637, -0.312378  , -0.6171399 ],\n",
              "        [ 0.7864578 , -0.9151786 ,  0.90779614]], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([[-0.38763815],\n",
              "        [ 0.41310883],\n",
              "        [-0.20387661]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_weights = relu_model.get_weights()\n",
        "initial_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Setting initial weights as 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0., 0., 0.],\n",
              "        [0., 0., 0.]], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_weights[0] = np.zeros(relu_model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(relu_model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(relu_model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(relu_model.get_weights()[3].shape)\n",
        "\n",
        "relu_model.set_weights(initial_weights)\n",
        "relu_model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "relu_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 73ms/step - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = relu_model.fit(X, y, epochs=100, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### You can clearly see how weights remain unchanged i.e. 0.\n",
        "- Same behavior is observed for Tanh AF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0., 0., 0.],\n",
              "        [0., 0., 0.]], dtype=float32),\n",
              " array([0., 0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.00664208], dtype=float32)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relu_model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Core Problems of Initializing Weights as 0: Comparison of Sigmoid, ReLU, and Tanh\n",
        "\n",
        "#### 1. **Symmetry Problem**\n",
        "- **Sigmoid**: If all weights are initialized to 0, every neuron in the network computes the same output during the forward pass. This results in identical gradients for all neurons during backpropagation, preventing the network from breaking symmetry. Consequently, all neurons in a layer learn the same features, reducing the model's capacity.\n",
        "---\n",
        "\n",
        "#### 2. **Vanishing Gradients**\n",
        "- **Sigmoid**: The Sigmoid activation function outputs values in the range (0, 1). When weights are initialized to 0, the gradients during backpropagation become very small, especially for neurons in deeper layers. This slows down or completely halts learning, as the updates to weights are negligible.\n",
        "- **ReLU**: ReLU does not suffer from vanishing gradients as severely as Sigmoid because its gradient is either 0 or 1. However, initializing weights to 0 exacerbates the \"dead neuron\" problem (explained below), which indirectly affects learning.\n",
        "- **Tanh**: Tanh outputs values in the range (-1, 1). While it has a broader range than Sigmoid, it still suffers from vanishing gradients when weights are initialized to 0. This is because the gradients for inputs near the extremes (-1 or 1) are very small, slowing down learning.\n",
        "\n",
        "\n",
        "#### 3. **Dead Neurons**\n",
        "- **Sigmoid**: Dead neurons are not a significant issue for Sigmoid because the function is always active (non-zero gradient) for all inputs. However, the vanishing gradient problem can still hinder learning.\n",
        "- **ReLU**: ReLU is prone to the \"dead neuron\" problem, where neurons output 0 for all inputs. If weights are initialized to 0, neurons may never activate, and their gradients remain 0 throughout training. This prevents these neurons from learning any features.\n",
        "- **Tanh**: Dead neurons are not a concern for Tanh, as it is always active for all inputs. However, the vanishing gradient problem can still significantly impact training.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Learning Dynamics**\n",
        "- **Sigmoid**: The combination of symmetry and vanishing gradients makes learning very slow or impossible when weights are initialized to 0. The network struggles to converge, especially for deeper architectures.\n",
        "- **ReLU**: While ReLU avoids vanishing gradients, the symmetry problem and dead neurons severely hinder learning when weights are initialized to 0. The network fails to utilize the full capacity of its neurons.\n",
        "- **Tanh**: Tanh suffers from both symmetry and vanishing gradients, leading to slow or stalled learning. While it has a broader range than Sigmoid, it still faces similar challenges when weights are initialized to 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec6aw2ft4nj2",
        "outputId": "80d399e4-b4b3-4a55-b3cc-cbf10b9f86b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 10)                30        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "sig_model = Sequential()\n",
        "\n",
        "sig_model.add(Dense(10, activation='sigmoid', input_dim=2))\n",
        "sig_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "sig_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiC2zbhh5E7u",
        "outputId": "4609c67b-fbf8-43f7-fb2f-bdd2ce92fe60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0.45937937,  0.33456415, -0.05582923,  0.01951486, -0.41542462,\n",
              "          0.60169095,  0.09893751, -0.5449407 ,  0.3087737 ,  0.03146398],\n",
              "        [ 0.14629573, -0.46702382, -0.25469103, -0.41645333, -0.34386063,\n",
              "         -0.59368217,  0.05847067, -0.20176691,  0.31180006, -0.48839682]],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[ 0.17302752],\n",
              "        [ 0.13931769],\n",
              "        [ 0.12821978],\n",
              "        [ 0.14196068],\n",
              "        [-0.26122752],\n",
              "        [-0.29126072],\n",
              "        [-0.6962638 ],\n",
              "        [ 0.03540218],\n",
              "        [-0.15104711],\n",
              "        [-0.39071724]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set parameters to 0\n",
        "sig_model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d2FB7EP46PXy"
      },
      "outputs": [],
      "source": [
        "initial_weights = sig_model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bik184Ij5aQJ"
      },
      "outputs": [],
      "source": [
        "initial_weights[0] = np.zeros(sig_model.get_weights()[0].shape)\n",
        "initial_weights[1] = np.zeros(sig_model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.zeros(sig_model.get_weights()[2].shape)\n",
        "initial_weights[3] = np.zeros(sig_model.get_weights()[3].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-u1RIZ_W5fXK"
      },
      "outputs": [],
      "source": [
        "sig_model.set_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryIDZEQs6fOa",
        "outputId": "98586a26-3422-4b4a-801c-d9f650abd17d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
              " array([[0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sig_model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6Vm5Nvfm6hkn"
      },
      "outputs": [],
      "source": [
        "sig_model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p_KvM6e62Xe",
        "outputId": "4ae45e3d-fe25-4fd2-d854-4832660db650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 68ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.4500 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6933 - accuracy: 0.4000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6918 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6917 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 0.5000 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6909 - accuracy: 0.5000 - val_loss: 0.6900 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6907 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6904 - accuracy: 0.5000 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6898 - accuracy: 0.5000 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6895 - accuracy: 0.5000 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6891 - accuracy: 0.5000 - val_loss: 0.6872 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6889 - accuracy: 0.5000 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6886 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6883 - accuracy: 0.5000 - val_loss: 0.6861 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6880 - accuracy: 0.5000 - val_loss: 0.6857 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6877 - accuracy: 0.5000 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6875 - accuracy: 0.5000 - val_loss: 0.6849 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6871 - accuracy: 0.5000 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6868 - accuracy: 0.5000 - val_loss: 0.6840 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6865 - accuracy: 0.5000 - val_loss: 0.6835 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6862 - accuracy: 0.5000 - val_loss: 0.6830 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6858 - accuracy: 0.5000 - val_loss: 0.6825 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6854 - accuracy: 0.5000 - val_loss: 0.6820 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6851 - accuracy: 0.5000 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6847 - accuracy: 0.5000 - val_loss: 0.6809 - val_accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6843 - accuracy: 0.5000 - val_loss: 0.6803 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6839 - accuracy: 0.5000 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6836 - accuracy: 0.5000 - val_loss: 0.6792 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6831 - accuracy: 0.5000 - val_loss: 0.6786 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6826 - accuracy: 0.5000 - val_loss: 0.6780 - val_accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6822 - accuracy: 0.5000 - val_loss: 0.6774 - val_accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6818 - accuracy: 0.5000 - val_loss: 0.6767 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6813 - accuracy: 0.5000 - val_loss: 0.6761 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6808 - accuracy: 0.5000 - val_loss: 0.6755 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6804 - accuracy: 0.5000 - val_loss: 0.6748 - val_accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5000 - val_loss: 0.6741 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6793 - accuracy: 0.5000 - val_loss: 0.6734 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.6789 - accuracy: 0.5000 - val_loss: 0.6727 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6784 - accuracy: 0.5000 - val_loss: 0.6719 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6778 - accuracy: 0.5000 - val_loss: 0.6712 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6773 - accuracy: 0.5000 - val_loss: 0.6705 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6768 - accuracy: 0.5000 - val_loss: 0.6698 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6763 - accuracy: 0.5000 - val_loss: 0.6691 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6759 - accuracy: 0.5000 - val_loss: 0.6683 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6752 - accuracy: 0.5000 - val_loss: 0.6676 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6746 - accuracy: 0.5000 - val_loss: 0.6669 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6741 - accuracy: 0.5000 - val_loss: 0.6661 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6735 - accuracy: 0.5000 - val_loss: 0.6652 - val_accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6729 - accuracy: 0.5000 - val_loss: 0.6645 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6724 - accuracy: 0.5000 - val_loss: 0.6636 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6718 - accuracy: 0.5000 - val_loss: 0.6628 - val_accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = sig_model.fit(X, y, epochs=100, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### You can see how weights from each node is same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y58LpwyB7HBr",
        "outputId": "d45719c1-8694-4f32-ef4c-8a7b302b1aba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.4549992 , -0.4549992 , -0.4549992 , -0.4549992 , -0.4549992 ,\n",
              "         -0.4549992 , -0.4549992 , -0.4549992 , -0.4549992 , -0.4549992 ],\n",
              "        [ 0.47610933,  0.47610933,  0.47610933,  0.47610933,  0.47610933,\n",
              "          0.47610933,  0.47610933,  0.47610933,  0.47610933,  0.47610933]],\n",
              "       dtype=float32),\n",
              " array([-0.11618948, -0.11618948, -0.11618948, -0.11618948, -0.11618948,\n",
              "        -0.11618948, -0.11618948, -0.11618948, -0.11618948, -0.11618948],\n",
              "       dtype=float32),\n",
              " array([[-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464],\n",
              "        [-0.06833464]], dtype=float32),\n",
              " array([0.06662544], dtype=float32)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sig_model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "9_DuSK3N7PDE",
        "outputId": "ad88b79f-6d43-4a76-fcaf-74844d79bdd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9600/9600 [==============================] - 6s 614us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "plot_decision_regions(X, y.astype('int'), clf=sig_model, legend=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary Table\n",
        "\n",
        "| Problem               | Sigmoid                     | ReLU                        | Tanh                       |\n",
        "|-----------------------|-----------------------------|-----------------------------|----------------------------|\n",
        "| Symmetry Problem      | Severe                     | Severe                     | Severe                    |\n",
        "| Vanishing Gradients   | Severe                     | Minimal                    | Moderate                  |\n",
        "| Dead Neurons          | Minimal                    | Severe                     | Minimal                   |\n",
        "| Learning Dynamics     | Slow or Stalled            | Stalled (due to symmetry)  | Slow or Stalled           |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### üîÄ Random Initialization (Uniform or Normal)\n",
        "Weights sampled from:\n",
        "\n",
        "- Uniform distribution: ùëà(‚àí1,1)\n",
        "- Normal distribution: ùëÅ(0,1)\n",
        "\n",
        "Still problematic in deep networks due to scale mismatch across layers.\n",
        "\n",
        "‚ùå Does not scale well as depth increases ‚Üí causes vanishing/exploding gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 2)                 6         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27\n",
            "Trainable params: 27\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(2, activation='tanh', input_dim=2))\n",
        "model.add(Dense(2, activation='tanh'))\n",
        "model.add(Dense(2, activation='tanh'))\n",
        "model.add(Dense(2, activation='tanh'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-1.1207736 ,  0.21734643],\n",
              "        [-0.17271364, -0.77336776]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.04837453, -0.22437608],\n",
              "        [-0.45672548,  1.052245  ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.42152262,  0.87691844],\n",
              "        [ 0.08844042, -0.7119583 ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[ 0.42137015, -0.9501635 ],\n",
              "        [ 1.0586025 ,  0.85648286]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[0.4492061 ],\n",
              "        [0.02688932]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# current weights\n",
        "initial_weights = model.get_weights()\n",
        "initial_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initialized the model weights with random small values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.01155635, -0.0212263 ],\n",
              "        [ 0.01082875,  0.01110417]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[ 0.01546927, -0.00570177],\n",
              "        [-0.0039839 , -0.0136782 ]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.00356961, -0.00745248],\n",
              "        [-0.00756   , -0.00906685]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[ 0.00604542, -0.00204902],\n",
              "        [ 0.00235312, -0.01094209]], dtype=float32),\n",
              " array([0., 0.], dtype=float32),\n",
              " array([[-0.01645667],\n",
              "        [ 0.00896417]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_weights[0] = np.random.randn(model.get_weights()[0].shape[0], model.get_weights()[0].shape[1]) * 0.01\n",
        "initial_weights[1] = np.zeros(model.get_weights()[1].shape)\n",
        "initial_weights[2] = np.random.randn(model.get_weights()[2].shape[0], model.get_weights()[2].shape[1]) * 0.01\n",
        "initial_weights[3] = np.zeros(model.get_weights()[3].shape)\n",
        "initial_weights[4] = np.random.randn(model.get_weights()[4].shape[0], model.get_weights()[4].shape[1]) * 0.01\n",
        "initial_weights[5] = np.zeros(model.get_weights()[5].shape)\n",
        "initial_weights[6] = np.random.randn(model.get_weights()[6].shape[0], model.get_weights()[6].shape[1]) * 0.01\n",
        "initial_weights[7] = np.zeros(model.get_weights()[7].shape)\n",
        "initial_weights[8] = np.random.randn(model.get_weights()[8].shape[0], model.get_weights()[8].shape[1]) * 0.01\n",
        "initial_weights[9] = np.zeros(model.get_weights()[9].shape)\n",
        "\n",
        "model.set_weights(initial_weights)\n",
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 1s 74ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.4750 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b5629707f0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=100, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.01147469, -0.02204683],\n",
              "        [ 0.01075004,  0.01189799]], dtype=float32),\n",
              " array([9.8479381e-07, 3.2763076e-06], dtype=float32),\n",
              " array([[ 0.01491161, -0.00678106],\n",
              "        [-0.00481028, -0.01528024]], dtype=float32),\n",
              " array([-8.9312198e-06, -1.0314295e-04], dtype=float32),\n",
              " array([[-0.00286228, -0.00708446],\n",
              "        [-0.00981009, -0.01012709]], dtype=float32),\n",
              " array([3.1925738e-04, 2.9818690e-05], dtype=float32),\n",
              " array([[ 0.00124211,  0.00193578],\n",
              "        [ 0.00046195, -0.00797138]], dtype=float32),\n",
              " array([-1.4086398e-04, -1.2696064e-06], dtype=float32),\n",
              " array([[-2.1841195e-03],\n",
              "        [ 1.7768452e-06]], dtype=float32),\n",
              " array([0.00184919], dtype=float32)]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
